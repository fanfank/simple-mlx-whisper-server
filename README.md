# MLX Whisper Server

High-performance HTTP server for audio transcription using MLX-Whisper. Compatible with OpenAI Whisper API specification.

NOTE: MOST OF THE CODE IS GENERATED BY AI, ONLY FOR STUDY PURPOSE, WILL BE UPDATED ONLY ACCORDING TO THE AUTHOR'S NEED 

## Features

- ✅ OpenAI Whisper API compatible - drop-in replacement
- ✅ Multiple audio format support (MP3, WAV, M4A, MP4, MPEG, WEBM), WAV and MP3 are the fastest

## Quick Start

### Prerequisites

- Python 3.12 or later
- macOS (for MLX support) or Linux
- 8GB+ RAM recommended

### Installation

```bash
git clone <repository-url>
cd mlx-whisper-server

# Install uv if not already installed
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create and activate virtual environment
uv venv --python 3.12
source .venv/bin/activate

# Install dependencies
uv sync --all-extras

# Start the server
uv run python -m src.main
```

## Usage

### Transcribe an audio file

```bash
#!/bin/bash
# Quick test - one line transcription
AUDIO_FILE="/path/to/your.mp3"

curl -X POST "http://127.0.0.1:9001/v1/audio/transcriptions" \
  -F "file=@$AUDIO_FILE" \
  -F "model=mlx-community/whisper-small"
```

## API Reference

### Endpoints

- `POST /v1/audio/transcriptions` - Transcribe audio file
- `GET /health` - Health check

## Architecture

```
src/
├── api/          # HTTP layer (FastAPI routes, handlers)
├── core/         # Configuration and utilities
├── services/     # Business logic layer
├── mlx/          # MLX integration
└── main.py       # Application entry point
```